#+TITLE: AGENDA - INTRODUCTION TO DATA SCIENCE
#+AUTHOR: Marcus Birkenkrahe
#+SUBTITLE: DSC 105 Data Structures Lyon College Fall 2025
#+STARTUP: overview hideblocks indent entitiespretty:
#+PROPERTY: header-args:R :session *R* :results output :exports both

* DONE Week 0

- [X] Course overview incl. Syllabus and infrastructure
- [X] Introduction to our tools - R, DataCamp, DataLab
- [X] First DataCamp lesson is due next week already

** Emacs + Org-mode + ESS or DataLab?

| Criterion   | Emacs + Org + ESS                  | Jupyter (DataLab)            |
|-------------+------------------------------------+------------------------------|
| *CS students* | Benefit, will follow               | Comfortable in either        |
| *Biologists*  | Likely unfamiliar; higher friction | Familiar User Interface      |
| *Undeclared*  | Risk of alienation, esp. early on  | Visual feedback/low barrier  |
| *Economists*  | Prefer notebook-style over Emacs   | Aligns with known econ tools |

* DONE Week 1: You've arrived on MaRs.
#+attr_html: :width 400px :float nil:
[[../img/mars.png]]

Today:
- [X] Review: Last week
- [X] Continue: Course Overview - DataCamp/datalab demo
- [X] *Research mixer on Tuesday, September 30 @Lyon - tinyurl.com/res-mix*
- [X] Compare: Jupyter notebook to Emacs + Org-mode + RSS
- [X] Compare: Google Colaboratory
- [ ] *Remember: DataCamp lesson deadline is Friday, 29 Aug, 1 pm*
- [ ] *First test available later today (complete by Friday 7 Sept)*

Next:
- [ ] Introduction to data science [lecture - [[https://github.com/yjwen/org-reveal/][org-reveal]]]
- [ ] Introduction to R.

** Review: Last week (0)

1. Name 1-3 tools that we're going to use in this course.
   #+begin_quote
   1) GitHub - Course materials
   2) DataCamp - Home assignment
   3) Canvas - Tests
   #+end_quote
2. How could you prepare a little before coming to class?
   #+begin_quote
   You could prepare by:
   - Looking through your own (digital or analog) notes
   - Looking at the whiteboard screenshots (available in GDrive)
   - Looking at the last lecture file (on GitHub)
   - Look at the Zoom recording (on Canvas)
   #+end_quote
3. What do you already know about "R"?
   #+begin_quote
   - High level programming language
   - Focus on statistical functions
   - Excels at visualization and data exploration
   - The Canvas course resources contain a link to an excellent free
     online tutorial for absolute beginners (and non-programmers)
   #+end_quote
4. What can you say about GitHub?
   #+begin_quote
   - A popular platform for software developers
   - Based on Torvald's (Creator of Linux) version control program Git
   - Data science students should register, create their own portfolio
     and complete the "Hello World" program to better understand Git
   #+end_quote
5. What will you have to do to pass this class?
   #+begin_quote
   - Complete online tests (only in Canvas)
   - Complete home assignments (mostly in DataCamp)
   - Complete a project ("Sprint reviews", in GDrive)
   - Pass a short one-on-one oral exam at the end of term ("Final
     exam") - optional
   #+end_quote

** DataCamp / datalab demo

1) Open ~datacamp.com~ and log in your (Lyon) account.

2) Enter "R" in the search field at the top.

3) Click on "Introduction to R" (should appear as the top result).

4) In the course dashboard under "Resources" click on "Course Notes".

5) This will bring you to an interactive ("Jupyter") notebook with one
   command already run, =str(mtcars)=:
   #+attr_html: :width 400px :float nil:
   [[../img/datalab.png]]

6) In the next block, try the AI assistant. Enter this prompt:
   #+begin_quote
   Build a scatterplot of miles-per-gallon as a function of weight
   using mtcars.
   #+end_quote
   #+attr_html: :width 400px :float nil:
   [[../img/datalab2.png]]

7) If it looks right to you, =Accept= it - now you hcave an executable
   code chunk.
   #+attr_html: :width 400px :float nil:
   [[../img/datalab3.png]]

8) Run it with the =Play= button or with the keyboard command =CTRL +
   ENTER= - the (minimally customized) scatterplot should appear:
   #+attr_html: :width 400px :float nil:
   [[../img/datalab4.png]]

9) Create another text cell and enter:
   #+begin_quote
   Print the top of the data frame with `head()`.
   #+end_quote
   #+attr_html: :width 400px :float nil:

10) Create another code cell, enter and run:
    #+begin_example R
    head(mtcars)
    #+end_example

** Research mixer - why you should do this
#+attr_html: :width 400px :float nil:
[[../img/research_mixer.png]]

- Doing research is a great excuse to build a relationship with a
  business: People love to help, especially techies!

- This is practical networking that can help you get an internship or
  a job: You can put it on your resume, too!

- Through research, you learn to update your knowledge, and you may
  find out about interesting applications that define your career!

- Science is at crossroads for multiple reasons: It's too bloated,
  it's too expensive, it's getting too difficult, and there's AI.

** Review (Monday):
#+attr_html: :width 400px :float nil:
#+caption: Rugby scrum
[[../img/scrum.jpg]]

1. Name at least three topics that are taught on DataCamp!
   #+begin_quote
   - Languages: R, Python, SQL, Julia
   - Data dashboard/visualization apps: Tableau, Power BI, R Shiny
   - Utilities: Shell, Git, AI, LLMs
   #+end_quote
2. What is a "Jupyter notebook"?
   #+begin_quote
   A Jupyter notebook is an interactive application originally
   designed for Julia, Python, and R, that enables literate
   programming (mixing text, code, output to make programs more
   readable for humans).
   #+end_quote
3. What's a sprint review?
   #+begin_quote
   A sprint review is a meeting where the project team (you) presents
   their project prototype (whatever it is they have done so far, if
   anything), takes questions from and asks questions to the client
   (me), and explains what they're going to do in the next sprint.
   #+end_quote
4. What's the deliverable of your first sprint review?
   #+begin_quote
   The deliverable of your first sprint review on September 12, 2025,
   is a *project proposal prototype* (which means that it doesn't have
   to be perfect). You can share a prototype of the prototype with me
   before the sh** hits the fan!
   #+end_quote
5. What's IMRaD?
   #+begin_quote
   IMRaD stands for the structure of a scientific communication
   (presentation, paper, report) - *Introduction* (what did you want to
   do?), *Method* (how did you do it?), *Results* (what did you find
   out?), and *Discussion* (what do your findings mean?).

   In our application of *Scrum*, we align IMRaD with four project
   sprint reviews.
   #+end_quote
6. Can you remember one R command (from the last class)?
   #+begin_src R :session *R* :results output :exports both
     str(mtcars)  # structure of the mtcars data frame
   #+end_src

   #+RESULTS:
   #+begin_example
   'data.frame':        32 obs. of  11 variables:
    $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
    $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
    $ disp: num  160 160 108 258 360 ...
    $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
    $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
    $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
    $ qsec: num  16.5 17 18.6 19.4 17 ...
    $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...
    $ am  : num  1 1 1 0 0 0 0 0 0 0 ...
    $ gear: num  4 4 4 3 3 3 3 4 4 4 ...
    $ carb: num  4 4 1 1 2 1 4 2 2 4 ...
   #+end_example

   #+begin_src R :session *R* :results output :exports both
     head(mtcars)
   #+end_src

   #+RESULTS:
   :                    mpg cyl disp  hp drat    wt  qsec vs am gear carb
   : Mazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4
   : Mazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4
   : Datsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1
   : Hornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1
   : Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2
   : Valiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1

   #+begin_src R :file plot.png :session *R* :results graphics output file :exports both
     plot(x=mtcars$wt,y=mtcars$mpg)
   #+end_src

   #+RESULTS:
   [[file:plot.png]]

** Compare: Google Colaboratory

1) Open Google Colab at =colab.research.google.com=
2) Create a =new notebook=
3) Run =str(mtcars)= - this should give an error
4) Change =Runtime type= to R
5) Enter the command again: =str(mtcars)= and run it.
6) Plot miles-per-gallon vs. weight for all cars in =mtcars=. (You can
   use CTRL-ALT-I for a new code chunk.)
   #+begin_example R
   plot(mtcars$wt,mtcars$mpg)
   #+end_example
7) Display the top of the data frame.
   #+begin_example R
   head(mtcars)
   #+end_example
8) Interestingly, Google Gemini gets this simple task completely wrong
   (prompt"Display the top of the mtcars data frame")
   #+attr_html: :width 400px :float nil:
   [[../img/gemini.png]]
9) It manages to explain and fix the error, but its new solution is
   unnecessarily long (R does not require ~print~ here).
   #+attr_html: :width 400px :float nil:
   [[../img/gemini2.png]]

** Review (Wednesday + DataCamp)

Review questions based on class and the first DataCamp lesson. With
necessary caveats based on years of professional and life experience.

1. How does the notebook work with the R or Python console?
   #+begin_quote
   Both the notebook and the console are *front-ends* where you enter
   commands. The notebook adds structure (code cells, text cells,
   graphics). The console is just a command-line. In both cases, the
   *back-end*, the R or Python interpreter (also called REPL -
   Read-Eval-Print-Loop), does the actual work of running your code.

   - Notebook = structured, richer front-end
   - Console = plain text front-end (command-line, shell)
   - REPL = back-end that executes
   #+end_quote

2. Can you access the REPL directly when you work in a notebook?
   #+begin_quote
   Not on Google Colab or DataCamp datalab. But when you work in Emacs
   (like I do) then you can. This is very useful for debugging
   (finding and fixing errors).
   #+end_quote

3. What then is the =terminal= that I can open in DataCamp datalab?
   #+begin_quote
   The =terminal= in datalab is a shell (CLI or command-line interface)
   that allows you to talk with the operating system (in this case,
   Linux). Let's look at that.
   #+end_quote

4. What kind of relationship is =str(mtcars)= or =head(mtcars,2)=?
   #+begin_quote
   These are *function applications*: a function (like ~str~ or ~head~) is
   applied to an object (like the =mtcars= dataset). This is the same
   idea as a mathematical functional relationship f(x).
   #+end_quote

5. What is the short formula for "data science"?
   #+begin_quote
   [RAW] *DATA* + [LITERATE] *CODE* + [APPLIED] *Stats* = [DECISION] *STORY*
   #+end_quote

6. What is the core purpose of data science (according to the lesson)?
   #+begin_quote
   DataCamp: Data science takes *raw data*, *cleans it*, and *uncovers
   patterns* that help make better *predictions* and improve outcomes.

   *Caveat:* Truly "raw" data do not exist (inside a
   computer). "Cleaning" the data is always with regard to an expected
   outcome or purpose. "Patterns" is still quite abstract - can you
   think of examples for patterns? Are there any patterns around you?
   #+end_quote

7. Why is data science so important today? What did people used to do
   in the past (without "data science")?
   #+begin_quote
   DataCamp: Because we generate more data than ever before through
   online purchases, apps, social media, and smart devices, and this
   data can be used to understand the world better.

   *Caveat:* Or it could be because we're more and more out of touch
   with people and things, and have begun to trust our machines more
   than our intuition (or our elders). Perhaps it's less about
   understanding and more about selling more stuff to strangers.
   #+end_quote

8. How do streaming services like Spotify or Netflix use data science?
   #+begin_quote
   DataCamp: They analyze your watching or listening habits with
   machine learning algorithms to predict and recommend what you might
   enjoy next.

   *Caveat:* What is your personal experience with online
   recommendations? Do they generally increase your enjoyment? Are
   online devices capturing data from you without explicit approval?
   #+end_quote

9. How do recommendations systems on platforms like Amazon make
   shopping feel personalized?
   #+begin_quote
   DataCamp: They analyze browsing history, past purchases, and trends
   from similar shoppers to predict what you might need next.

   *Caveat:* What does your browsing and purchasing history really say
   about you as a person? How important is shopping in your life?
   Where is "enjoyable shopping" on the list of your top priorities?
   #+end_quote

10. What is the main focus of a data analyst? Why would a business
    need a data analyst?
    #+begin_quote
    DataCamp: Data analysts clean and organize "raw data", then create
    charts, graphs, and dashboards to explain what's happening right
    now. Businesses may need such a person because insights gained
    from data may help managers make informed, evidence-based
    decisions.

    *Caveat*: What do you think how many decisions are made in business?
    What does play a bigger role in a time-critical situation,
    data-driven analysis or gut feeling, work and life experience?
    #+end_quote

** Project proposal due in 2 weeks ("First Scrum sprint review")
#+attr_html: :width 400px :float nil:
[[../img/first_review.png]]

- Put your team mates' names, your topics and comments on the project
  page in Canvas by Friday September 12, 11:59 pm.

- Use the cancelled session on Wednesday, September 3, to meet as a
  team and work out the proposal draft.

- I have created a mock-up entry including a link to a GDrive folder
  with a fake AI-generated proposal, which is not bad at all though:
  it is specific, complete, and potentially interesting and relevant.

- *Can you use AI to generate your proposal?* Yes, but 1) you have to be
  say that and how you used AI, and 2) you need to be able to talk
  about it freely and openly, i.e. you have to make it your own.

- It is actually easier, more rewarding, more likely to succeed, and
  more instructive if you come up with your own topic and proposal.

- In the project information table, *please follow my example*:
  1) Full names of all team members!
  2) Full title of topic (or topics if you have a choice) linked
     directly to the proposal!
  3) Link to your GDrive folder (make sure it is shared across Lyon)!
     #+attr_html: :width 400px :float nil:
     [[../img/sharing.png]]

- For a similar student project from Fall 2024 that lead to a
  published paper, see:
  #+begin_quote
  Del Gobbo, C., Birkenkrahe, M. (2025). Generative AI Tools in Higher
  Education: A Case Study of Student Usage At A Small Liberal Arts College.
  In: Proc. 19th Int. Technology, Education and Development Conf (INTED25),
  3-4 March 2025, 315-324; URL: https://doi.org/10.21125/inted.2025.0142
  #+end_quote

*** Fake Proposal: Study Habits and Academic Performance
#+attr_html: :width 400px :float nil:
[[../img/fake.png]]

A project for DSC 105 (Introduction to Data Science)
by Jim Jones, Jane Doe, and John James.

This proposal was generated by ChatGPT-5. The references are real.

**** Problem description

We want to analyze the relationship between student study habits (time
spent studying, study environment, use of groups, sleep, etc.)  and
academic performance (exam/quiz scores, GPA). The idea is to identify
which factors contribute most to success and whether there are
patterns across students.

**** Reason

This problem is interesting because study habits are something every
student can control, but it’s not always clear which strategies are
most effective. The results could provide insights for us and our
peers about how to optimize study time, sleep, and group work.

**** Constraints

- *Technical:* Collecting enough quality data may be difficult; survey
  responses may be incomplete or inaccurate.
- *Conceptual:* Correlation does not equal causation—this project can
  suggest patterns but not prove what “causes” performance.
- *Personal:* We will need to balance data collection with other
  coursework, so we may not be able to gather a large dataset.

**** Goals (and non-goals)

- *Goals:*
  1. Design and distribute a short survey, then collect at least 20
     responses.
  2. Clean and preprocess the data (handle missing values, normalize
     hours).
  3. Create summary statistics and visualizations (scatter plots,
     boxplots, bar charts).
  4. Build a simple predictive model (e.g., linear regression or
     classification).
  5. Write a short report and present findings.

- *Non-goals:*
  - We will not try to build a large-scale or professional predictive
    system.
  - We will not claim to establish causality between habits and
    grades.
  - We will not use highly complex machine learning methods (e.g.,
    neural networks).

**** Metrics

The project will be successful if:
- We collect at least 20 usable survey responses.
- Our analysis produces at least three clear, interpretable
  visualizations.
- We identify at least two meaningful relationships or patterns (e.g.,
  sleep correlates with higher GPA).
- We can present a clear and concise report with recommendations.

**** References

1. Kuh GD, Kinzie J, Buckley JA, Bridges BK, Hayek JC.
   *What Matters to Student Success: A Review of the Literature.*
   National Postsecondary Education Cooperative; 2006.

2. McGuire SY, McGuire S.
   *Teach Yourself How to Learn: Strategies You Can Use to Ace Any Course at Any Level.*
   Stylus Publishing; 2018.

3. University of California, Berkeley. "Study Strategies."
   Student Learning Center. Accessed August 2025.
   https://slc.berkeley.edu/study-strategies

**** Comments

We considered doing a project on social media usage and its effect on
grades, but decided on study habits because we can collect the data
more easily and it feels more relevant to daily student life. Our main
concern is participation—we hope enough classmates will respond
honestly to the survey.

* DONE Week 2: Data Collection and Storage & Infrastructure (Sep 5)
#+attr_html: :width 600px :float nil:
#+caption: Data infrastructure (Source: alcorfund.com)
[[../img/infrastructure.png]]

- [X] Projects - deadline is looming.
- [X] Review - Data Collection and Storage & infrastructure

** Projects - 1st sprint review is coming!

- All but four of you still have to fill in the project table in
  Canvas.

- You'll get (timely) feedback from me either via chat or in the
  proposal document (if you let me edit it).

- One group project so far was going out of scope: Don't bite off more
  than you can chew. Remember: focus on data, and on what you know!

** Review (Last Friday - Aug 29 & DataCamp lesson 2)

You can find most of the answers either in the DataCamp lesson (I used
the slides to prepare these), or on the Whiteboard screenshots from
the past week.

1. What's a REPL and how does it relate to data science?
   #+begin_quote
   REPL = Read-Eval-Print-Loop - interactive programming environment
   that READs user input, EVALuates it, PRINTs the result, and LOOPs
   back for another input.
   #+end_quote
   #+attr_html: :width 600px :float nil:
   [[../img/repl.png]]

2. What's different when doing data science with C/C++ or with
   R/Python?
   #+begin_quote
   C/C++ are compiled languages, while R/Python are interpreted
   languages that can be used with a REPL.
   #+end_quote

3. What are web data (that are interesting to a data scientist)?
   #+begin_quote
   Web data are events (what the user did), timestamp (when he did
   it), and user information (who he is). These data are enough to
   create living process maps and identify web data flows.
   #+end_quote
   #+attr_html: :width 600px :float nil:
   #+caption: Process mining diagram (order process)
   [[../img/process.png]]

4. What's an API (in the context of data science)?
   #+begin_quote
   An API (Application Programming Interface) is a set of rules and
   endpoints that lets programs request and exhange data with external
   systems - e.g. Google Maps, a database of stocks, Twitter/X feeds.

   See also: Kubernetes API Server (see Google Chat).
   #+end_quote
   #+begin_src R :session *R* :results output :exports both
     ## Install if you don't already have it
     ## install.packages("httr")
     ## install.packages("jsonlite")

     library(httr)
     library(jsonlite)

     ## Example: Get a random joke from the "Official Joke API"
     url <- "https://official-joke-api.appspot.com/random_joke"

     response <- GET(url)            # Send request
     content <- content(response, "text")  # Get response as text
     data <- fromJSON(content)       # Parse JSON into an R list

     print(data$setup)               # Show joke setup
     print(data$punchline)           # Show punchline
   #+end_src

   Example output:
   #+begin_example
   : [1] "What's the difference between a seal and a sea lion?"
   : [1] "An ion! "
   #+end_example

5. What's the difference between qualitative and quantitative data?
   Examples?
   #+begin_quote
   - *Quantitative data* represent a quantity (Lat. quantus - "how
     much?"):
     + They deal with (mathematical) numbers.
     + They can be measured but not observed (directly).
     + They are highly abstracted (via math).
     + Examples: Height [in], price [$], percentage [%].

   - *Qualitative data* represent a quality (Lat. qualis - "what
     kind?"):
     + They deal with (language) descriptions
     + They can be observed but not measured (directly).
     + They are lowly abstracted (via language).
     + Examples: Tall, cheap, vague.
   #+end_quote

6. What's a relational database?
   #+begin_quote
   A relational database is software that allows you to store data in
   tables (or relations) made up of rows (or records) and columns (or
   fields) where:
   - Each table holds data about one type of thing (e.g. "students")
   - Relationships between tables are defined by keys (e.g. student ID)
   - You can define, store, control, query and combine data using SQL.
   #+end_quote

7. What's a query language? What's an example?
   #+begin_quote
   A language to articulate data queries, for example querying a table
   in a relational database management system using SQL, as in the
   query: =SELECT customer_name FROM customers;=
   #+end_quote

8. What do you need to consider when storing data?
   #+begin_quote
   - *Location* (e.g. parallel storage solutions or the cloud, or locally)
   - *Data category* (e.g. unstructured or tabular)
   - *Retrieval* (e.g. NoSQL for document (collection-based), or SQL for
     relational (table-based) databases.
   #+end_quote

9. What's the connection between structuredness of data and decision
   complexity? Compare adding prices at a cash register with deciding
   to sell your business.
   #+begin_quote
   The more complex (aka difficult, hard to describe, overwhelming) a
   decision is, the less structured are the data that support it.
   #+end_quote

10. What are the top cloud providers in the world?
    #+begin_quote
    - Amazon with Amazon Web Services (as in "Amazon Prime") ~30-40%
    - Microsoft with Azure (as in "Microsoft Windows") ~20-30%
    - Alphabet with Google Cloud (as in "Google Cloud Shell") ~10-20%
    #+end_quote

11. What does it mean to "scale data storage"?
    #+begin_quote
    When collecting large amounts of different types data from multiple
    sources, the "scaling" question is "how much, what type, and how
    fast"? If an application (e.g. for storage) scales, it can store
    small and (arbitrarily) large data volumes. To scale, technology
    either has to be invented or adapted - with computers, scale always
    comes at a price.

    E.g. for databases, you can scale vertically (bigger servers), or
    horizontally (more servers). What to do depends on your data.
    #+end_quote

12. What's a "data pipeline"?
    #+begin_quote
    A data pipeline is a workflow, a prescribed series of steps or
    stages that is used to retrieve, load, and store data, to better
    control individual steps and (ideally) automate the entire process.

    The term "pipeline" is used whenever segments are combined so that
    the output of the previous segment is the input of the next,
    e.g. in the following shell command, which pipes the string into a
    file and then counts the characters of the string:
    #+end_quote
    #+begin_src bash :results output
      echo "Hello" | tee hello.txt |  wc -c
      cat hello.txt
    #+end_src

13. What's "ETL" and how is it used (think of an example)?
    #+begin_quote
    - ETL stands for the "Extract", "Transform", "Load" data pipeline.
    - Example: autonomous vehicle operation:
      1. Retrieve real-time traffic data (e.g. "rain", "stop sign")
      2. Transform retrieved data for analysis (e.g. create table)
      3. Load transformed data into container (e.g. SQLite database)
    - When an ETL pipeline is well set up, it can be automated. In the
      case of automated vehicles, operation otherwise wouldn't be
      possible.
    #+end_quote

** Bonus: Kubernetes ([[https://chat.google.com/room/AAAALkEATEU/TnlGXFrrgt4/TnlGXFrrgt4?cls=10][see Google Chat]])
#+attr_html: :width 600px :float nil:
[[../img/kubernetes.png]]

[[https://kubernetes.io]["Kubernetes"]] (from the Greek word for "navigator" or "captain") is a
container technology - applications (like a data notebook) are
"containerized" so that the user doesn't have to worry about what's
under the hood. This is a modern version of the infrastructure setup
that I explained last week - just to show you how this looks like in
the wild:

- Kubernetes "API Server" is the front desk where your request
  goes. Now, the system will take care of your request (e.g. for data
  analysis) using any available resources (GPUs, CPUs, RAM etc.)
- The "Kubelet" is the local manager of your resources. It uses the
  "Pod Sandbox".
- Your models, data pipelines, or notebooks are packaged as Docker
  images (compressed) so that they can be reproduced. They are fetched
  from the "Image Registry".
- Each of your requests undergoes "Pod stages" (that's the job
  lifecycle)
- When you stop or the job/request is finished, the container is
  terminated, and volumes (memory) is released.

For data scientists, this setup means: Scalability (run 1 or 1000
experiments), reproducibility (environment is containerized and
identical across runs), resource efficiency (scheduled), isolation
(jobs don't compete with one another), and automation (cleanup).

* DONE Week 3: Guest lecture & Introduction to R (Sep 8, 10, 12)
#+attr_html: :width 300px :float nil:
[[../img/troxel2.png]]

- [X] Test 2 is live (known review questions) - by Sept 14
- [X] Presentation this Wednesday - Brandon Smith
- [X] Monday: Finish Introduction to Data Science
- [ ] By Friday: Review DataCamp lesson / Start with R
- [ ] By Friday: First sprint review due!
- [ ] By Sunday: Install R on your PC (submit screenshot to Canvas)

** Introduction to data science (continued)

- [X] Data science skill set
- [X] IT vs. data science skills stack
- [X] Data science use cases

** Guest presentation: Data science and Software Engineering in Space

- Prepare some questions for our speaker.
- Think about data transfer, use of data in space.
- Which programming languages will be most useful?
- Consider doing an internship with this or another company.

** Introduction to R

- [ ] Why are we using R?
- [ ] Obtaining and installing R from CRAN
- [ ] Running R scripts on the command-line

** Linux vs. Windows vs. MacOS for Data Science

| Aspect               | Windows                                                                 | macOS                                                                 | Linux                                                                 |
|-----------------------+------------------------------------------------------------------------+------------------------------------------------------------------------+----------------------------------------------------------------------|
| Ease of Setup         | Familiar UI, easy install of mainstream tools (Anaconda, RStudio, VS Code). Some ML libraries harder due to dependency issues. | Smooth setup, especially for Python/R. Comes with Unix-like terminal. Package management via Homebrew. | Steeper learning curve, but most flexible. Native package managers (apt, yum, pacman). Great for reproducibility. |
| Ecosystem & Compatibility | Wide commercial software support (Excel, PowerBI, Tableau). Some scientific tools first optimized here. | Good support for both productivity tools and developer tools. MATLAB, R, Python, and Julia work well. | Best support for open-source data science tools (TensorFlow, PyTorch, R, Julia). Most cloud/cluster systems run Linux. |
| Programming Environment | PowerShell improving, but still weaker than Bash/Zsh. WSL2 provides Linux environment inside Windows. | Unix-based terminal (zsh/bash) works well for scripting and automation. | Native Unix environment; preferred by many data scientists for scripting, automation, HPC. |
| Performance           | Can run heavy workloads with GPU (CUDA support strong). WSL2 adds overhead. | Stable performance, good optimization for Apple Silicon (M1/M2 chips). GPU support weaker (esp. NVIDIA CUDA). | Excellent performance, especially for servers and clusters. Best environment for GPU and HPC tasks. |
| Package Management    | Conda and pip work, but dependency management sometimes messy.          | Homebrew + Conda/pip make installations cleaner.                       | apt/yum/pacman + Conda/pip. Reproducible environments easier (e.g., Docker). |
| Machine Learning/AI   | Best CUDA GPU support for deep learning. WSL2 makes Linux tools accessible. | Limited CUDA support (NVIDIA GPUs rare). Apple Silicon ML acceleration still maturing. | Native CUDA/cuDNN, best support for ML frameworks, common in research/production. |
| Collaboration         | Widely used in business. Easy integration with Microsoft tools (Excel, Teams). | Popular in academia and industry. Plays well with both business and dev environments. | Dominant in academia, research labs, and cloud environments. Matches production servers. |
| Cost & Licensing      | Paid license, but widely available in workplaces.                      | Expensive hardware, but OS updates free.                               | Free and open source. Many distributions available. |
| Best Fit For          | Data scientists in business/enterprise settings needing Microsoft ecosystem. | Users who want a balance of usability and Unix power (good for mixed productivity + coding). | Researchers, engineers, and power users needing control, reproducibility, and alignment with production/cloud. |

** Review (Wednesday)

1. What kind of data science is required if you have many decisions to
   make and have big data available?
   #+begin_quote
   Drawing on Cassie Kozyrkov's infographic from the lecture, this
   means that you need "machine learning".
   #+end_quote
2. What kind of data science is required if you don't have any
   decisions to make and are just curious, or if you have a few
   decisions but not much data?
   #+begin_quote
   Drawing on Cassie Kozyrkov's infographic from the lecture, this
   means that you need "data analysis".
   #+end_quote

3. What is ~Rscript~?
   #+begin_quote
   Rscript is an alternative front-end (user-facing application) for
   use in R scripts (programs). =Rscript --help= gives usage, =man
   Rscript= provides a manual page for ~Rscript(1)~.
   #+end_quote
4. What is CRAN?
   #+begin_quote
   CRAN is the Comprehensive R Archive Network that provides access to
   R software, packages, and documentation. An equivalent for Python
   is PyPI, the Python package index.
   #+end_quote
5. When you download R to a Windows computer from CRAN, which format
   does it have?
   #+begin_quote
   The R download for Windows from CRAN is a precompiled binary - you
   download the .exe installer first and then unpack it to the PC.
   #+end_quote
6. What are "vector", "list", and "data frame" in R?
   #+begin_quote
   Vector, list and data frame are special data structures in R -
   so-called containers to manage data collections.
   #+end_quote

** Review (DataCamp) "Preparation, Exploration, Visualization"

Open datacamp.com/datalab. Make sure you're logged in the "Lyon
College Fall 2025" workspace (infinite number of notebooks for you).

Incidentally, this is what I suggest you do whenever you go through a
DataCamp lesson - especially when it is code-heavy like this one.

You can check my notebook later: [[https://tinyurl.com/datacamp-review-3][tinyurl.com/datacamp-review-3]] (This
opens to the =notebook.ipynb= file. Open the files (on the right) to
open the notebook that I uploaded (auto-generated by ChatGPT btw).

1. What needs to be done in this dataset?
   #+begin_example
        Name Age Size Country
   1    Sara  27 1.77 Belgium
   2     Lis  30 5.58     USA
   3 Hadrien  NA 1.80      FR
   4     Lis  30 5.58     USA
   #+end_example

   Get the data (from the web):
   #+begin_src R :session *R* :results output :exports both
     df <- read.csv("https://tinyurl.com/cleaning-csv") # read CSV data into data frame
     str(df)  # structure of data frame
     df
   #+end_src

   #+RESULTS:
   #+begin_example
   'data.frame':        4 obs. of  4 variables:
    $ Name   : chr  "Sara" "Lis" "Hadrien" "Lis"
    $ Age    : int  27 30 NA 30
    $ Size   : num  1.77 5.58 1.8 5.58
    $ Country: chr  "Belgium" "USA" "FR" "USA"
   Name Age Size Country
   1    Sara  27 1.77 Belgium
   2     Lis  30 5.58     USA
   3 Hadrien  NA 1.80      FR
   4     Lis  30 5.58     USA
   #+end_example

2. Clean up country code and size.

   #+begin_src R :session *R* :results output :exports both
     df$Country[1] <- "BE"  # change to country code
     df$Size[df$Size==5.58] <- 1.70  # change inches to meters
     str(df)
   #+end_src

   #+RESULTS:
   : 'data.frame':      4 obs. of  4 variables:
   :  $ Name   : chr  "Sara" "Lis" "Hadrien" "Lis"
   :  $ Age    : int  27 30 NA 30
   :  $ Size   : num  1.77 1.7 1.8 1.7
   :  $ Country: chr  "BE" "USA" "FR" "USA"

3. Fix the name of "Lisa" (listed as "Lis"):

   #+begin_src R :session *R* :results output :exports both :noweb yes
     df$Name[2]
   #+end_src

   #+RESULTS:
   : [1] "Lis"

   #+begin_src R :session *R* :results output :exports both :noweb yes
     df$Name[2] <- "Lisa"
     df
   #+end_src

   #+RESULTS:
   : Name Age Size Country
   : 1    Sara  27 1.77      BE
   : 2    Lisa  30 1.70     USA
   : 3 Hadrien  NA 1.80      FR
   : 4     Lis  30 1.70     USA

4. What is the purpose of removing duplicates in a dataset?
   #+begin_quote
   To ensure that each observation (row) is unique.
   #+end_quote

   Remove duplicate row:
   #+begin_src R :session *R* :results output :exports both
     df      # original data frame with duplicate row
     df[-4,] -> df   # duplicate row removed
     df
   #+end_src

   #+RESULTS:
   :      Name Age Size Country
   : 1    Sara  27 1.77      BE
   : 2     Lis  30 1.70     USA
   : 3 Hadrien  NA 1.80      FR
   : 4     Lis  30 1.70     USA
   : Name Age Size Country
   : 1    Sara  27 1.77      BE
   : 2     Lis  30 1.70     USA
   : 3 Hadrien  NA 1.80      FR

5. What are methods to handle missing values?
   #+begin_quote
   *Impute* (replace intelligently, e.g. by an average), drop, or keep.
   #+end_quote

   Replace ~NA~ value by column average (~mean~).
   #+begin_src R :session *R* :results output :exports both
     df
     df$Age[Name="Hadrien"]  # extract third element of "Age" column
     df$Age[3]
     df$Age[3] <- as.integer(mean(df$Age[-3])) # impute mean for missing value
     df
   #+end_src

   #+RESULTS:
   #+begin_example
        Name Age Size Country
   1    Sara  27 1.77      BE
   2     Lis  30 1.70     USA
   3 Hadrien  28 1.80      FR
   [1] NA
   [1] 28
   Name Age Size Country
   1    Sara  27 1.77      BE
   2     Lis  30 1.70     USA
   3 Hadrien  28 1.80      FR
   #+end_example

6. What is the main goal of EDA?
   #+begin_quote
   The main goal of Exploratory Data Analysis (EDA) is to explore the
   data, formulate hypotheses, and assess characteristics, e.g. about
   correlation, trends, patterns. It happens after data preparation.
   #+end_quote

   Create a statistical ~summary~ for the data frame.
   #+begin_src R :session *R* :results output :exports both
     summary(df) # statistical summary for the data frame df
   #+end_src

   #+RESULTS:
   :      Name                Age            Size         Country
   :  Length:4           Min.   :27.0   Min.   :1.700   Length:4
   :  Class :character   1st Qu.:28.5   1st Qu.:1.700   Class :character
   :  Mode  :character   Median :30.0   Median :1.735   Mode  :character
   :                     Mean   :29.0   Mean   :1.742
   :                     3rd Qu.:30.0   3rd Qu.:1.778
   :                     Max.   :30.0   Max.   :1.800
   :                     NA's   :1

7. What does *Anscombe's quartet* illustrate in the context of EDA?
   #+begin_quote
   The Anscombe quartet shows the importance of visualizing data even
   if the statistical properties are very similar.
   #+end_quote

   Summarize the data in the (built-in) =anscombe= data set.
   #+begin_src R :session *R* :results output :exports both
     summary(anscombe[c("x1","x2","y1","y2")])
   #+end_src

   #+RESULTS:
   :        x1             x2             y1               y2
   :  Min.   : 4.0   Min.   : 4.0   Min.   : 4.260   Min.   :3.100
   :  1st Qu.: 6.5   1st Qu.: 6.5   1st Qu.: 6.315   1st Qu.:6.695
   :  Median : 9.0   Median : 9.0   Median : 7.580   Median :8.140
   :  Mean   : 9.0   Mean   : 9.0   Mean   : 7.501   Mean   :7.501
   :  3rd Qu.:11.5   3rd Qu.:11.5   3rd Qu.: 8.570   3rd Qu.:8.950
   :  Max.   :14.0   Max.   :14.0   Max.   :10.840   Max.   :9.260

   Visualize two of the =anscombe= distributions.
   #+begin_src R :file ../img/anscombe.png :session *R* :results file graphics output :exports both
     par(mfrow=c(1,2), pty='s')
     plot(anscombe$x1, anscombe$y1, col="red",  pch=19) # linearly correlated
     plot(anscombe$x2, anscombe$y2, col="blue", pch=9 ) # non-linearly correlated
   #+end_src

   #+RESULTS:
   [[file:../img/anscombe.png]]

8. What does 'Knowing your data' mean? Which R functions that you know
   already deliver this?
   #+begin_quote
   1. Preview data values (=head=)
   2. View structure (=str=)
   3. Descriptive stats (=summary=)
   4. Visualize (=plot=)
   5. Look for correlations (=cor=)
   6. Look for outliers (=boxplot=)
   #+end_quote

9. What is "labeling" in data visualizations, and why is it important?
   #+begin_quote
   Labeling helps viewers understand what each axis, title, and legend
   represents. Units and data sources are also important.
   #+end_quote
   Code example:
   #+begin_src R :file ../img/labeling.png :session *R* :results file graphics output :exports both
     par(mfrow=c(1,2),pty='s')
     plot(mtcars$wt,mtcars$mpg) # unlabeled
     plot(mtcars$wt,mtcars$mpg,
          main="32 cars from `mtcars`",
          xlab="Weight [tons]",
          ylab="Miles-per-gallon") # labeled
   #+end_src

   #+RESULTS:
   [[file:../img/labeling.png]]

10. Which picture or photo do you know that's "worth a thousand words"?
    #+attr_html: :width 400px:
    #+caption: 16-year old German soldier crying when he is captured, WWII
    [[../img/hitler_youth_crying.jpg]]

    - Others that came to my mind instantly:
      #+begin_quote
      - [[https://www.witf.io/wp-content/uploads/2020/02/iwo-jima-rosenthal-520748-1-1920x1080.jpg][Battle of Iwo Jima]] (1945)
      - [[https://www.gannett-cdn.com/-mm-/f40f3606fa7f520417c0c9e02d7aa7a371d004ba/r=x513&c=680x510/local/-/media/USATODAY/USATODAY/2013/04/28/war-icons-003-4_3.jpg][Saigon Execution]] (1968)
      - [[https://www.njspotlightnews.org/wp-content/uploads/sites/123/2024/07/Donald-Trump-assassination-attempt-July-13-2024.jpg][Trump assassination]] (2024)
      #+end_quote

11. What are dashboards in data science, and what are they good for?
    #+begin_quote
    - Dashboards group relevant information in one place
    - Real-time information helps viewers to keep track
    - Dashboards can be customized to different data needs
    - Dashboards can easily be overwhelming (design issues)
    - Interactive dashboards can help extract features
    #+end_quote

12. What are dashboards definitely not good for?
    #+begin_quote
    - Data preparation, cleaning and transformation
    - Explorative Data Analysis (because they are fixed)
    #+end_quote

* DONE Week 4: Expo & more R & webinar & 2nd sprint review (Sep 15, 17, 19)
#+attr_html: :width 200px :float nil:
[[../img/expo.png]]

- [X] Career expo - why you should go
- [X] 1st Sprint Review (project proposals) graded with feedback
- [X] 2nd Sprint Review deliverable is a literature review (Oct 10)
- [X] Webinar on Git and GitHub this Friday 12 pm
- [X] This week: Continue the DataCamp lesson review
- [X] Last lesson of the "Understanding data science" course (due Fri)
- [X] 2nd sprint review instructions and example
- [X] Test 4: Will include test questions based on the DataCamp lesson
- [X] Next week: Start Introduction to R lesson on DataCamp
- [X] Use a datalab notebook to try things out

** Why (and how) should you attend the Lyon Career Expo?
#+attr_html: :width 400px:
[[../img/careerFair.png]]

- Explore opportunities for future career paths.
- Build connections with local employers.
- Show initiative. Dress the part. Bring your resume.
- See our new career center director, Cassidy Mitchell

Careers often unfold in unpredictable ways. Some things are in your
control: Being diligent, curious, responsible, act honorably, listen
more than you speak. Those qualities will carry you far, no matter
your career path.

** Projects - update and next steps
#+attr_html: :width 400px:
[[../img/literature.jpeg]]

- These were very good beginner proposals! Best ever in my view!

- I took away a point if you violated the constraints.

- Completeness and compliance is more important than creativity.

- Getting something (anything!) done is more important than ambition.

- Most of you are biting off more than you can chew.

- Make the problem as small as you can, get results, then expand.

- Remember to stick to what you already know and expand from there.

- Don't do what I do but do what I tell you and don't do myself.

- Next: Move on from "What" to "How". Deliverable: *Literature Review.*

- Did I use AI to prepare my feedback? For 3/6 feedback reports.
  #+begin_quote
  1) I read your proposal twice, taking notes along the way.
  2) I fed your proposal and my assignment text into ChatGPT.
  3) I asked for a section-by-section critique draft.
  4) I copied the draft and edited it for content.
  5) I think the feedback is now more structured than before.
  6) I know that the feedback is now no longer 100% mine.
  7) I won't be able to do this for the 2nd sprint review.

  I'm going to demonstrate to you how much more time you will have to
  spend when you opt to enroll stupid generative AI for a creative
  task: Now I need to re-validate all proposals to be sure of you.
  #+end_quote

- Did you use generative AI tools to prepare the proposal? How?

** Review questions on your projects
#+attr_html: :width 400px:
[[../img/titanic.jpg]]

I promised that you would get an opportunity to check your
understanding of your own work especially if you had AI
assistance. But even if you did not, you need to be able to answer
with confidence and skill to your own creative work.

g1. *Fixture congestion* (Diego, Matheus, Frederico)
#+begin_quote
What is AUC/ROC?
#+end_quote
#+begin_quote
AUC/ROC is an evaluation method for binary classification model:
- ROC (Receiver Operating Characteristic curve) plots true positive
  rate against false positive rate. Shows how well the model
  separates two classes (e.g. injury vs. no injury)
- AUC (Area Under the Curve) is a single number that summarizes the
  ROC curve, ranging from 0.5 (no better than random guessing) to
  1.0 (perfect classification).
#+end_quote
#+attr_html: :width 400px:
[[../img/auc_roc.png]]
2. *Titanic survivors* (Olivia, Ava)
   #+begin_quote
   You mention that you "want to analyze demographics from the
   surviving Titanic passengers to see if factors like race, age,
   gender, and economic and social status influenced who survived."

   What are the data contained in the referenced Kaggle dataset? Where
   do the data originate from?
   #+end_quote
   #+begin_quote
   The dataset contains 12 features:
   1) Passenger ID
   2) Survived
   3) Passenger class
   4) Name
   5) Sex
   6) Age
   7) Number of siblings aboard
   8) Number of parents/children
   9) Ticket number
   10) Passenger fare
   11) Cabin number
   12) Port of embarkation

   Most notably, *race* is not captured, and cannot be inferred
   either. Economic and social status could be inferred but "status"
   is a vague category (hard to measure - means different things to
   different people in different places).

   The original source seems to be the Titanic passenger manifest but
   I did not find this information on Kaggle who altered the
   dataset. This is not the raw historical dataset.
   #+end_quote
3. *Morse code* (Matthew)
   #+begin_quote
   This is clearly not AI generated since the proposal misses
   idiosyncratically out on several assignment categories. An
   imperfect but intelligent proposal is almost always a clear sign of
   human creativity.

   Still, for good measure: You write that using Scrum (not an
   acronym) is used so that you "are encouraged as aspiring Data
   Scientists to continually evaluate and learn through our
   experiences with attention to our personal skill stack and
   problem-solving abilities as they relate to the task at hand."

   A mouthful! Very typical for AI by the way. Question: What is
   really the core of Scrum for agile project management?
   #+end_quote
   #+begin_quote
   The core of the Scrum agile management method is to manage complex
   work through short, iterative cycles and continuous feedback. To do
   this Scrum employs a set of roles (like "product owner"), artifacts
   (like "sprint backlog", items selected for current sprint), and
   events (like "sprint review").
   #+end_quote
4. *Retail data* (Prabhat, Riya, Avash)
   #+begin_quote
   Some formulations are typically AI-vague, and the unstructured
   references could give AI away - but the proposal reads personal.

   Question: In your comments, you write that "the chest dataset"
   (which you're not using) "would solve a meaningful problem in data
   science."

   Which problem are you referring to here?
   #+end_quote
5. *Time management* (Surendra, Saksham, Jenish)
   #+begin_quote
   What are the main findings and recommendations of the two papers
   that you cited? What data were used by the authors?
   #+end_quote
   #+begin_quote
   Answer:
   1) Wilson et al. (2021) found correlations between students' time
      management skills and academic success, based on 140 students at
      the Austraila Defence Force Academy. Recommends to implement
      time management training and further research.
   2) Terzi et al. (2024) found that students who manage their time
      experienced an enhanced quality of life (because they now had
      more time for fun aka leisure activities). Based on a sample of
      213 Turkish students, 18-35 years. Recommends training.
   #+end_quote
6. *Fentanyl in mice* (Levi)
   #+begin_quote
   Lots of additional documentation here - curious to hear if you or
   any of your collaborators benefitted from AI assistance.

   You could show your skill level by explaining the difference
   between a "Type 1 or Type 2 error" (mentioned in "Constraints").
   #+end_quote
   #+begin_quote
   - *Type I error* (false positive): You conclude that there is an
     effect when there really isn't one because you found something
     (positive) that isn't there (false). Example 1: You conclude that
     DOI (some amphetamine?) does mitigate withdrawal symptoms in mice
     when it does actually not do that. Example 2: When predicting for
     spam, false positives are messages marked as spam (what you are
     looking for) that are not spam.
   - *Type II error* (false negative): You fail to detect an effect that
     actually exists because you didn't find something (negative) that
     is there (false). Example 1: You fail to detect a real effect of
     DOI on withdrawal symptoms. Example 2: You miss spam messages.
   #+end_quote

** Webinar: Friday 12 pm - Introduction to Git and GitHub (see Google Chat)

- Renowned researcher Dr. Blaine Mooers Oklahoma U Dept speaks on Git
  and GitHub and on how he uses it in his biomolecular research.

- [[https://oklahoma.zoom.us/j/94661289236?pwd=WHdLYkRhMHFFQmlPUHhqQU1uNDRoZz09&from=addon][Join the meeting via Zoom]]. If interested in future webinars, write
  to Blaine to be put on his mailing list.

- At Matthew's initiative, *let's meet at 12 pm in Derby 239* to watch
  it together. We'll make this part of our class - since the webinar
  will be published, *this is an assignment for next week*!

- *Abstract:* The program Git is used to back up computer programs and
  text-based documents.  It also supports the tracking of changes and
  the synching of files in collaborative work.  It is associated with
  GitHub, which provides access to online repositories.  These
  repositories can be private or public; you can have both kinds for
  free as an academic.  Some features of Git and GitHub are confusing
  to new users.  I will attempt to demystify them by presenting my
  simple approach to utilizing Git and GitHub in my everyday work and
  in my work on a GitHub site for the Data Science Workshop as part of
  a DISC-funded summer pilot project.

- This talk will be recorded and posted early next week at this site:
  https://mediasite.ouhsc.edu/Mediasite/Channel/python/browse/null/most-recent/null/0/null.

** Review: First Sprint Review Post Mortem

1. What does "Scrum" stand for?
   #+begin_quote
   It stands for an agile management methodology that is designed to
   improve client-developer communication and make complex projects
   more flexible.
   #+end_quote

2. What's a "Type I" and what's a "Type II" error?
   #+begin_quote
   - Type I error (false positives): You see an effect that isn't
     really there. Example: You falsely identify messages as spam
     though they are not.
   - Type II error (false negative): You miss an effect that really
     exists. Example: You miss a spam message that you falsely
     identify as not spam.
   #+end_quote

3. What should you remember about references in your project?
   #+begin_quote
   - They need to be *consistently* cited (pick a style,
     e.g. AMA), and they need to be *complete* (as defined by the style
     you picked - a URL e.g. or the title of a site is not a complete
     reference).

   - If you can you need to cite relevant sources *inline* when you make
     a non-trivial claim.

   - You need to *validate* their accuracy and identify their
     *limitations* (e.g. small sample size, missing methodology, etc.)

   - You need to read enough to know what they're claiming to be *true*.
   #+end_quote

4. What should you remember about data in your project?
   #+begin_quote
   - Always find out where the data *originally* came from (even if
     you're not interested in history).

   - Always validate the *quality* of the data (by source, format,
     etc.).
   #+end_quote

5. What should you remember about methods in your project?
   #+begin_quote
   - When you use a method, you must study it first and make sure it
     is appropriate.

   - Find other *use cases* that used the same or a similar method.

   - Make sure you understand the *method* (how), the *metric* (what is
     measured and how), and the *meaning* (why is this method used).
   #+end_quote

6. Do you need to update your proposal according to my feedback?
   #+begin_quote
   - Yes, you should, *but you don't need to re-submit it*. Keep
     building your project documentation. Remember to document as much
     as possible - both your results and your way of working.

   - Put differently: If I look at your proposal again and I notice
     that you couldn't be bothered to update it according to my
     feedback, that will destroy trust between you (developers) and me
     (process owner).
   #+end_quote

7. What is the purpose of the sprint review?
   #+begin_quote
   - To present the *results* of your last sprint to the process owner.
   - To identify what you did or did not *achieve* in the last sprint.
   - To get an idea what to do (or not to do) in the *next* sprint.
   #+end_quote

8. What is a "backlog"? What is a "sprint backlog"?
   #+begin_quote
   - A backlog is a list of all your (unfinished) tasks for the
     project. You draw it up at the start when the requirements are
     clear.

   - A sprint backlog accordingly is a list of all your (unfinished)
     tasks for the current sprint.

   - When asked you should be able to name elements of your backlog
     (namely, what it is that you are currently working on).
   #+end_quote

9. What is a confidence index?
   #+begin_quote
   A number betwen 0 and 10 that reflects your current confidence in
   the project.

   If this number goes up, all is good and you can take a break.

   If this number goes down, you need to identify the source of
   trouble and bring it back up.
   #+end_quote

10. What is the purpose, the task and the deliverable of the current
    (second) sprint?
    #+begin_quote
    - *Purpose:* Identify the *method* - how exactly you're going to
      approach your project task.

    - *Task*: Find sources - scientific, technical, social, personal,
      etc. - that help you identify how to proceed. These could be
      blogs, videos, papers, books, or people.

    - *Deliverable*: Use Google's NotebookLM research sandbox
      application to generate a podcast and/or a video based on your
      uploaded sources, and work with the on-board AI to identify your
      method(s).
    #+end_quote

** Second Sprint Review with NotebookLM
#+attr_html: :width 600px:
[[../img/notebooklm2025.png]]

- See the complete assignment for this sprint in Canvas.

- Here is what I did:
  1) Generate feedback on the proposal.
  2) Update the proposal.
  3) Upload updated proposal and all sources (PDF) to "Sources".
  4) Generate a detailed prompt for the 2nd sprint review video:
     #+begin_quote
     Present this update to my professor, who has already given me feedback on our Sprint 1 proposal.

     Begin by briefly describing what we accomplished in Sprint 1:
     - We developed a proposal to study the relationship between student
       study habits (hours, sleep, group work, study environment) and
       academic performance (GPA, quiz/exam scores).
     - We explained why the problem matters, outlined constraints (small
       sample size, correlation ≠ causation, workload), and set realistic
       goals (survey, data cleaning, visualization, simple modeling,
       report).
     - We also included non-goals (no causality claims, no large-scale
       predictive systems, no advanced machine learning).

     Then transition to methodology for Sprint 2:
     - Mention that, based on professor feedback, we increased the survey
       target from 20 to 30 responses, clarified our variables, and added
       explicit data privacy measures.

     Summarize relevant literature consulted:
     - Kuh et al. (2006) What Matters to Student Success
     - McGuire & McGuire (2018) Teach Yourself How to Learn
     - UC Berkeley Student Learning Center, Study Strategies (2025)
     - Aljaffer et al. (2024) The impact of study habits and personal
       factors on the academic achievement performances of medical students.

     From these sources, highlight themes: consistent routines, adequate
     sleep, active learning.

     Outline the methodology as a clear step sequence:
     1) Design and distribute an anonymous survey (30+ responses,
        covering study hours, sleep, environment, group/solo, GPA/quiz
        scores).
     2) Collect and clean data (handle missing values, standardize
        formats).
     3) Perform exploratory data analysis (scatterplots, boxplots,
        descriptive statistics).

     Build a simple regression or decision tree model to explore
     relationships, without claiming causality.

     Write a concise report with visualizations, patterns, and recommendations.

     End with next steps:
     - Finalize and distribute the survey.
     - Begin collecting responses over the next two weeks.
     - Set up the R analysis pipeline to be ready for cleaning and EDA
       once data arrives.
     - Aim to have preliminary data and visualizations ready for the next
       sprint.

     Tone: professional but student-level; the video should sound like a
     progress report to a professor.
     #+end_quote
  5) Generate the video overview.
  6) Generate three notes in "Chat" - two of them based on
     AI-suggested questions (project design, project variables), and
     one on my own question (What's the worst that could happen to
     this project).
  7) Added the notes to the "Studio".

- Let's watch the video (4 min) so you can see what I'm after.

- And here is an example litmap for one of my references:
  #+attr_html: :width 600px:
  [[../img/litmap2025.png]]

- Check out my GDrive folder: [[https://tinyurl.com/2nd-sprint-demo][tinyurl.com/2nd-sprint-demo]]

- Deadline (hard): Friday, October 10, 2025.

** Review (Wednesday)

1. What does the function =str(df)= show when applied to a data frame in
   R?
   #+begin_quote
   It shows the structure: number of rows, columns, and each
   variable’s type and first few preview values.
   #+end_quote

   #+begin_src R :session *R* :results output :exports both :noweb yes
     str(mtcars)
   #+end_src

2. In the expression ~df$Name==5.58~, what does the ~==~ operator achieve?
   #+begin_quote
   It selects all rows of the ~Name~ column vector of the ~df~ data frame
   where the "Name" column equals "Lis".
   #+end_quote

   #+begin_src R :session *R* :results output :exports both :noweb yes
     mtcars$mpg
     mtcars$mpg==21.0
     mtcars$mpg[mtcars$mpg==21.0]
   #+end_src

   #+RESULTS:
   :  [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4 10.4 14.7 32.4 30.4 33.9 21.5 15.5
   : [23] 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7 15.0 21.4
   : [1]  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
   : [19] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
   : [1] 21 21

3. In the command ~df$Country[df$Country == "Belgium"] <- "BE"~, what is
   happening?
   #+begin_quote
   All rows in the "Country" column equal to "Belgium" are replaced
   with "BE".
   #+end_quote

   #+begin_src R :session *R* :results output :exports both :noweb yes
     mtcars$mpg[mtcars$mpg==21.0] <- 100
     mtcars$mpg
   #+end_src

   #+RESULTS:
   : [1] 100.0 100.0  22.8  21.4  18.7  18.1  14.3  24.4  22.8  19.2  17.8  16.4  17.3  15.2  10.4  10.4  14.7  32.4
   : [19]  30.4  33.9  21.5  15.5  15.2  13.3  19.2  27.3  26.0  30.4  15.8  19.7  15.0  21.4

4. What is the difference between the operators ~=~ and ~<-~, for example
   in ~x = 5~ or ~x <- 5~ ?
   #+begin_quote
   They're both assignment operators in R (no difference), but the
   arrow operator can also be used in the other direction: ~x -> 5~.
   #+end_quote

   #+begin_src R :session *R* :results output :exports both :noweb yes
     c(1,2,3) -> x
     x * 2
     y = c(5,6,7)
     y
   #+end_src

   #+RESULTS:
   : [1] 2 4 6
   : [1] 5 6 7

5. In the code =df[-4, ]=, what does the =-4= do?
   #+begin_quote
   It removes the 4th row from the data frame =df=.
   #+end_quote

   #+begin_src R :session *R* :results output :exports both :noweb yes
     rownames(mtcars)
     rownames(mtcars)[-2]
   #+end_src

   #+RESULTS:
   #+begin_example
    [1] "Mazda RX4"           "Mazda RX4 Wag"       "Datsun 710"          "Hornet 4 Drive"      "Hornet Sportabout"  
    [6] "Valiant"             "Duster 360"          "Merc 240D"           "Merc 230"            "Merc 280"           
   [11] "Merc 280C"           "Merc 450SE"          "Merc 450SL"          "Merc 450SLC"         "Cadillac Fleetwood" 
   [16] "Lincoln Continental" "Chrysler Imperial"   "Fiat 128"            "Honda Civic"         "Toyota Corolla"     
   [21] "Toyota Corona"       "Dodge Challenger"    "AMC Javelin"         "Camaro Z28"          "Pontiac Firebird"   
   [26] "Fiat X1-9"           "Porsche 914-2"       "Lotus Europa"        "Ford Pantera L"      "Ferrari Dino"       
   [31] "Maserati Bora"       "Volvo 142E"
   [1] "Mazda RX4"           "Datsun 710"          "Hornet 4 Drive"      "Hornet Sportabout"   "Valiant"            
    [6] "Duster 360"          "Merc 240D"           "Merc 230"            "Merc 280"            "Merc 280C"          
   [11] "Merc 450SE"          "Merc 450SL"          "Merc 450SLC"         "Cadillac Fleetwood"  "Lincoln Continental"
   [16] "Chrysler Imperial"   "Fiat 128"            "Honda Civic"         "Toyota Corolla"      "Toyota Corona"      
   [21] "Dodge Challenger"    "AMC Javelin"         "Camaro Z28"          "Pontiac Firebird"    "Fiat X1-9"          
   [26] "Porsche 914-2"       "Lotus Europa"        "Ford Pantera L"      "Ferrari Dino"        "Maserati Bora"      
   [31] "Volvo 142E"
   #+end_example

** Finish "Preparation, Exploration, Visualization" Demo in R

Go to the unfinished datalab notebook and let's finish it together:
https://www.datacamp.com/datalab/w/3d575f61-3463-4b1c-b213-b0b4cb47d7c8/edit

*

* DONE Week 5: The R environment (Sep 22, 24, 26)
#+attr_html: :width 150px: 
#+CAPTION: RStudio Ball Logo (Source: rstudio.com)
[[../img/3_rstudioball.png]]

- [X] Test 4 is live (end of first DataCamp course)
- [X] Download your DataCamp certificate (to LinkedIn)
- [X] Next lesson: "Introduction to R: Basics" (Sept 28)
- [X] Home assignment: Weekly snack budget (Sept 29)
- [X] Systematic introduction to R
  
** DONE Programming assignment explanation

- The assignment tests assignment, calculation, output, data type
  checking. Apart from the ~class~ function, everything is contained in
  the first DataCamp lesson "Introduction to R: Basics".

- The top of your submission should look like this:
  #+attr_html: :width 400px:
  [[../img/assignment1.png]]

- Below this explanatory header follows the text + code + output that
  leads to the expected outcome.

- To share, notice that you need to add me (birkenkrahe@lyon.edu) as
  "Viewer", then you can copy the link and submit it to Canvas.
  #+attr_html: :width 400px:
  [[../img/assignment_submission.png]]

- We will discuss my sample solution next week.


** DONE On finding a literature review ([[https://chat.google.com/room/AAAALkEATEU/_zJhcqiKsiM/md-ig0qyGaM?cls=10][Google Chat post]])

- Online literature searches are never 100% successful.

- Litmap app (like Google search) is not transparent - luck of the draw.

- More important than anything: You need to be able to identify which
  *literature search strategy* you employed during your project.
  
- Real researchers use conferences, proceedings, events, social media,
  journals, books, but most importantly human experts to find papers.

** DONE Review (R console)

1. Why would you use  R on the command-line?
   #+begin_quote
   Command-line R is the most flexible, portable, and reproducible way
   to use R, especially in Linux and research workflows. Allows remote
   and *headless* (no GUI) use and integration of Unix tools (pipeline,
   text processing, pattern matching, etc.).
   #+end_quote

2. Why don’t people use R or Python for everything?  
   #+begin_quote
   Different languages excel at different tasks (systems, real-time,
   mobile, embedded, etc.); there’s no one-size-fits-all.
   #+end_quote

3. How can you check where the ~R~ and ~Rscript~ executables live on a
   Unix-like system?
   #+begin_src bash :results output
     which Rscript
     which R
   #+end_src

   #+RESULTS:
   : /usr/bin/Rscript
   : /usr/bin/R

4. What does running R in batch mode have that running R in scripting
   mode does not have?
   #+begin_quote
   The batch mode runs in the background and provides processing
   times for user, system, and total time elapsed.
   #+end_quote
   #+begin_src bash :results output
     echo "str(mtcars)" > test.R  # creating a test file
     R CMD BATCH test.R
   #+end_src

5. How and where can you get help on: =Rscript= and =mtcars=
   #+begin_quote
   - You can get help on the program ~Rscript~ on the command-line with
     =man Rscript=.
     
   - You can get help on the built-in dataset ~mtcars~ on the R console
     with =?mtcars= or =help(mtcars)=.
   #+end_quote

6. How do you get into, and how do you quit the R console?
   #+begin_quote
   - Open a terminal (aka shell aka command-line interface).
   - Enter =R= to enter the R console.
   - Enter =q()= followed by =y= or =n= to quit the R console.
   #+end_quote

* DONE Week 6: R options and packages (Sep 29, Oct 1, Oct 3)

- [X] Don't forget test 5 (deadline Sunday). Test 6 live today.

- [X] Don't forget home assignment 2 (deadline Monday).

- [X] Don't forget the 2nd DataCamp lesson on R (vectors) by Sunday.

- [X] Don't forget the 2nd sprint review deadline (by next Friday).

** Review: Weekly Snack Budget Assignment

- A few of you put all the code into one code block. If you do that,
  you're not using the full power of the notebook. 

- When the assignment provides sample input and sample output, you
  need to reproduce these values exactly. In this example:
  #+attr_html: :width 600px :float nil:
  [[../img/assignment.png]]

- I have subtracted 1 point for incomplete submission this time.
  
- Reproducing data/code/results and testing programs is a key activity
  in the life of every data scientist (> 50% of your time.

- My sample solution is available at [[https://tinyurl.com/weekly-snacks][tinyurl.com/weekly-snacks]].

- For late submissions you can get 50% of the points. If you waited
  until 2 hours before the due date, you've left it too late. You
  should find time to attempt an assignment as early as you can.

- If an assignment is due Monday, don't expect me to reply on Sunday.

- If you use commands not covered in class or DataCamp, I will query
  you.

- If you used AI to complete your assignment, you need to say it in
  the preamble and identify how exactly you used it.

- Examples:   
  #+begin_quote
  What does the ~cat~ command do (in R, on the shell)? 
  #+end_quote

  #+begin_src R :session *R* :results output :exports both
    x <- 100
    print(cat("Print ", x)) # `cat` prints a NULL character
    print(cat("Print ", x, '\n')) 
  #+end_src

  #+RESULTS:
  : Print  100 
  : NULL

  #+begin_quote
  What does the ~paste~ command do? (Different from ~cat~ and ~print~)?
  #+end_quote

  #+begin_src R :session *R* :results output :exports both
    foo <- "I am"
    bar <- "concatenated"
    paste(foo, bar,x)
    print(paste(foo,bar,x)) # adds nothing: last result is always printed
  #+end_src

  #+RESULTS:
  : [1] "I am concatenated 100"
  : [1] "I am concatenated 100"

  #+begin_quote
  Do you have to use ~if~ and ~else~ to check if the =total= budget is
  =within_budget=?
  #+end_quote

  #+begin_src R :session *R* :results output :exports both
    x <- 100
    greater100 <- x > 0
    greater100
  #+end_src

  #+RESULTS:
  : [1] TRUE

  #+begin_quote
  What does the ~mode~ command do? How is it different from ~class~?
  #+end_quote
  
  #+begin_src R :session *R* :results output :exports both
    x <- 100
    mode(x)   # storage mode
    class(x)  # object class mode
  #+end_src

  #+RESULTS:
  : [1] "numeric"
  : [1] "numeric"

  #+begin_quote
  What does ~typeof~ do? How is it different from ~mode~ and ~class~?
  #+end_quote  

  #+begin_src R :session *R* :results output :exports both
    typeof(x)  ## R internal storage mode of an object
  #+end_src

  #+RESULTS:
  : [1] "double"

** Review (Environment)

1. Why do you need to cite software that you used in your references?
   #+begin_quote
   You need to cite software that you used in order to make your
   research *replicable*.
   #+end_quote

2. What does the function ~getwd()~ do in R?
   #+begin_quote
   ~getwd()~ shows the *current working directory* where R reads and
   writes files.
   #+end_quote

3. How do you change the working directory in R?
   #+begin_quote
   Use the ~setwd()~ function with either a *relative* or *absolute path*.
   #+end_quote

4. What is the difference between a relative path and an absolute path
   in R?
   #+begin_quote
   *Relative* paths are given from the *current* location (e.g., =..=),
   while *absolute* paths start from the computer's *root* or home
   directory (e.g., =/home/user=, or =C:\Users\=).
   #+end_quote
   
5. How can you run a *shell* command such as ~pwd~ from *inside R*?  
   #+begin_quote
   Use the ~system()~ function, e.g., ~system('pwd')~.
   #+end_quote

6. What does the R command ~system("ls -la | wc -l")~ do? What is this
   kind of command called?
   #+begin_quote
   This Unix *pipeline* command lists all files in the directory (=ls=)
   and then counts the number of lines in the listing (=wc=). Here, =-la=
   and =-l= are command *flags* or *options* that modify the behavior.
   #+end_quote

7. Can you also run single R commands like ~str~ on ~mtcars~ on the
   command-line? Tip: check the man page for ~Rscript~.
   #+begin_src bash :results output :exports both
     Rscript -e 'str(mtcars)'
     Rscript -e 'print("hello")'
   #+end_src

8. Can you run an R command inside a shell command inside an R
   command? 
   #+begin_src R :session *R* :results output :exports both
     ## From inside R run Rscript on the shell on an R print() function
     system("Rscript -e \'print(\"hello\")\'") # special signs are escaped
   #+end_src
   
9. Can you run an R command inside a shell command inside an R
   command inside a shell command? 
   #+begin_src R :session *R* :results output :exports both
     ## From inside R run Rscript on the shell on an R system() function
     ## Inside the system() function, run the shell command `pwd`.
     system("Rscript -e \'system(\"pwd\")\'") 
   #+end_src

10. What's the command to quit or exit the R console?
    #+begin_quote
    The command to quit or exist is ~quit()~ or ~q()~.
    #+end_quote

** Review: R display options

In R, the graphic display options are stored in ~options~.

Open a new workbook in DataCamp datalab.

Open a terminal. Open R.

1. How would you show this "~options~" object?
   #+begin_src R :session *R* :results output :exports both
     str(options())    #  <--- str() is a generic function
     options()         #  <--- not `options` (unknown)
   #+end_src
2. How would you extract the display options value for the ~prompt~?
   #+begin_src R :session *R* :results output :exports both :noweb yes
     options()$prompt  # <--- access the list element `prompt`
   #+end_src
3. How would you find out what type of object this ~options~ is?
   #+begin_src R :session *R* :results output :exports both :noweb yes
     class(options())  #  <--- not class(options)
   #+end_src
4. How would you find out more about this object?
   #+begin_example
     help(options)   <--- produces the man page
   #+end_example

** Review: R packages

1. Where does R get its packages from?
   #+begin_quote
   From ~options$repos~. Typically, this is https://cloud.r-project.org,
   which will pick a CRAN mirror closest to you.
   #+end_quote

2. What is a mirror site?
   #+begin_quote
   A website (typically for downloading software) that is identical to
   a central site like https://cloud.r-project.org on CRAN.
   #+end_quote

3. What are the steps to install an R package, for example ~data.table~?
   #+begin_quote
   - Find out if the package is already installed with
     ~installed.packages()~
   - If it's not there, install it with ~install.packages("data.table")~
   - If it cannot be installed, check ~options$repos~ to see where R is
     trying to get it from.
   - If ~repos~ is OK (e.g. ~cloud.r-project.org~), check at CRAN if your
     package perhaps requires a different version of R.
   - If that's the case, ~install.packages("remotes")~ and then use
     ~install_version~ from the ~remotes~ package.
   #+end_quote

4. What are the steps to be able to use a package like ~MASS~ in your R
   session?
   #+begin_quote
   1) Install it (~install.packages~)
   2) Load it (~library~)
   3) Use it (~search~)
   #+end_quote

5. What's an "R session"?
   #+begin_quote
   An R session is a running instance of the R software that loads R
   environment variables and enables you to run R commands
   interactively on a console to complete statistical computing tasks.
   #+end_quote

6. What is "base R"?
   #+begin_quote
   Base R is the software that contains R's core functions and
   packages that come with R by default without installing anything
   extra. Included are tools for data types, statistics, graphics, and
   programming.
   #+end_quote

7. What does the message ~"Save workspace image? [y/n/c]"~ at the end of
   an R session mean - after entering ~q()~.
   #+begin_quote
   R is asking whether to save the objects of the current session
   (e.g. variables you defined, packages you loaded) in memory into a
   (binary) file ~.RData~.
   #+end_quote

8. What is a "generic function", what are examples of generic
   functions in R?
   #+begin_quote
   A generic function adapts to different objects that you feed
   it. E.g. ~str~ works with ~data.frame~, dates, vectors, lists.
   #+end_quote
   #+begin_src R :session *R* :results output :exports both
     str(c(1,2,3))  # structure of vector
     str(mtcars)    # structure of a built-in data.frame
     str(as.Date("2025-10-03")) # structure of today's date
   #+end_src

   #+RESULTS:
   #+begin_example
    num [1:3] 1 2 3
   'data.frame':	32 obs. of  11 variables:
    $ mpg : num  21 21 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 ...
    $ cyl : num  6 6 4 6 8 6 8 4 4 6 ...
    $ disp: num  160 160 108 258 360 ...
    $ hp  : num  110 110 93 110 175 105 245 62 95 123 ...
    $ drat: num  3.9 3.9 3.85 3.08 3.15 2.76 3.21 3.69 3.92 3.92 ...
    $ wt  : num  2.62 2.88 2.32 3.21 3.44 ...
    $ qsec: num  16.5 17 18.6 19.4 17 ...
    $ vs  : num  0 0 1 1 0 1 0 1 1 1 ...
    $ am  : num  1 1 1 0 0 0 0 0 0 0 ...
    $ gear: num  4 4 4 3 3 3 3 4 4 4 ...
    $ carb: num  4 4 1 1 2 1 4 2 2 4 ...
   Date[1:1], format: "2025-10-03"g
   #+end_example

   #+begin_src R :session *R* :results output :exports both :noweb yes
     methods(str)
     methods(headg)
   #+end_src

   #+RESULTS:
   : [1] str.data.frame* str.Date*       str.default*    str.dendrogram* str.logLik*     str.POSIXt*    
   : see '?methods' for accessing help and source code
   : [1] head.array*      head.data.frame* head.default*    head.ftable*     head.function*   head.matrix     
   : see '?methods' for accessing help and source code

9. How can you see all currently available datasets?
   #+begin_src R :session *R* :results output :exports both
     data()
   #+end_src

   #+RESULTS:
   #+begin_example
   Data sets in package ‘datasets’:

   AirPassengers                   Monthly Airline Passenger Numbers 1949-1960
   BJsales                         Sales Data with Leading Indicator
   BJsales.lead (BJsales)          Sales Data with Leading Indicator
   BOD                             Biochemical Oxygen Demand
   CO2                             Carbon Dioxide Uptake in Grass Plants
   ChickWeight                     Weight versus age of chicks on different diets
   DNase                           Elisa assay of DNase
   EuStockMarkets                  Daily Closing Prices of Major European Stock Indices, 1991-1998
   Formaldehyde                    Determination of Formaldehyde
   HairEyeColor                    Hair and Eye Color of Statistics Students
   Harman23.cor                    Harman Example 2.3
   Harman74.cor                    Harman Example 7.4
   Indometh                        Pharmacokinetics of Indomethacin
   InsectSprays                    Effectiveness of Insect Sprays
   JohnsonJohnson                  Quarterly Earnings per Johnson & Johnson Share
   LakeHuron                       Level of Lake Huron 1875-1972
   LifeCycleSavings                Intercountry Life-Cycle Savings Data
   Loblolly                        Growth of Loblolly pine trees
   Nile                            Flow of the River Nile
   Orange                          Growth of Orange Trees
   OrchardSprays                   Potency of Orchard Sprays
   PlantGrowth                     Results from an Experiment on Plant Growth
   Puromycin                       Reaction Velocity of an Enzymatic Reaction
   Seatbelts                       Road Casualties in Great Britain 1969-84
   Theoph                          Pharmacokinetics of Theophylline
   Titanic                         Survival of passengers on the Titanic
   ToothGrowth                     The Effect of Vitamin C on Tooth Growth in Guinea Pigs
   UCBAdmissions                   Student Admissions at UC Berkeley
   UKDriverDeaths                  Road Casualties in Great Britain 1969-84
   UKgas                           UK Quarterly Gas Consumption
   USAccDeaths                     Accidental Deaths in the US 1973-1978
   USArrests                       Violent Crime Rates by US State
   USJudgeRatings                  Lawyers' Ratings of State Judges in the US Superior Court
   USPersonalExpenditure           Personal Expenditure Data
   UScitiesD                       Distances Between European Cities and Between US Cities
   VADeaths                        Death Rates in Virginia (1940)
   WWWusage                        Internet Usage per Minute
   WorldPhones                     The World's Telephones
   ability.cov                     Ability and Intelligence Tests
   airmiles                        Passenger Miles on Commercial US Airlines, 1937-1960
   airquality                      New York Air Quality Measurements
   anscombe                        Anscombe's Quartet of 'Identical' Simple Linear Regressions
   attenu                          The Joyner-Boore Attenuation Data
   attitude                        The Chatterjee-Price Attitude Data
   austres                         Quarterly Time Series of the Number of Australian Residents
   beaver1 (beavers)               Body Temperature Series of Two Beavers
   beaver2 (beavers)               Body Temperature Series of Two Beavers
   cars                            Speed and Stopping Distances of Cars
   chickwts                        Chicken Weights by Feed Type
   co2                             Mauna Loa Atmospheric CO2 Concentration
   crimtab                         Student's 3000 Criminals Data
   discoveries                     Yearly Numbers of Important Discoveries
   esoph                           Smoking, Alcohol and (O)esophageal Cancer
   euro                            Conversion Rates of Euro Currencies
   euro.cross (euro)               Conversion Rates of Euro Currencies
   eurodist                        Distances Between European Cities and Between US Cities
   faithful                        Old Faithful Geyser Data
   fdeaths (UKLungDeaths)          Monthly Deaths from Lung Diseases in the UK
   freeny                          Freeny's Revenue Data
   freeny.x (freeny)               Freeny's Revenue Data
   freeny.y (freeny)               Freeny's Revenue Data
   infert                          Infertility after Spontaneous and Induced Abortion
   iris                            Edgar Anderson's Iris Data
   iris3                           Edgar Anderson's Iris Data
   islands                         Areas of the World's Major Landmasses
   ldeaths (UKLungDeaths)          Monthly Deaths from Lung Diseases in the UK
   lh                              Luteinizing Hormone in Blood Samples
   longley                         Longley's Economic Regression Data
   lynx                            Annual Canadian Lynx trappings 1821-1934
   mdeaths (UKLungDeaths)          Monthly Deaths from Lung Diseases in the UK
   morley                          Michelson Speed of Light Data
   mtcars                          Motor Trend Car Road Tests
   nhtemp                          Average Yearly Temperatures in New Haven
   nottem                          Average Monthly Temperatures at Nottingham, 1920-1939
   npk                             Classical N, P, K Factorial Experiment
   occupationalStatus              Occupational Status of Fathers and their Sons
   precip                          Annual Precipitation in US Cities
   presidents                      Quarterly Approval Ratings of US Presidents
   pressure                        Vapor Pressure of Mercury as a Function of Temperature
   quakes                          Locations of Earthquakes off Fiji
   randu                           Random Numbers from Congruential Generator RANDU
   rivers                          Lengths of Major North American Rivers
   rock                            Measurements on Petroleum Rock Samples
   sleep                           Student's Sleep Data
   stack.loss (stackloss)          Brownlee's Stack Loss Plant Data
   stack.x (stackloss)             Brownlee's Stack Loss Plant Data
   stackloss                       Brownlee's Stack Loss Plant Data
   state.abb (state)               US State Facts and Figures
   state.area (state)              US State Facts and Figures
   state.center (state)            US State Facts and Figures
   state.division (state)          US State Facts and Figures
   state.name (state)              US State Facts and Figures
   state.region (state)            US State Facts and Figures
   state.x77 (state)               US State Facts and Figures
   sunspot.month                   Monthly Sunspot Data, from 1749 to "Present"
   sunspot.year                    Yearly Sunspot Data, 1700-1988
   sunspots                        Monthly Sunspot Numbers, 1749-1983
   swiss                           Swiss Fertility and Socioeconomic Indicators (1888) Data
   treering                        Yearly Treering Data, -6000-1979
   trees                           Diameter, Height and Volume for Black Cherry Trees
   uspop                           Populations Recorded by the US Census
   volcano                         Topographic Information on Auckland's Maunga Whau Volcano
   warpbreaks                      The Number of Breaks in Yarn during Weaving
   women                           Average Heights and Weights for American Women


   Use ‘data(package = .packages(all.available = TRUE))’
   to list the data sets in all *available* packages.
   #+end_example

10. How can you see all currently available datasets for a specific
    package that you installed, e.g. ~MASS~?
    #+begin_src R :session *R* :results output :exports both
      data(package="MASS")
    #+end_src

    #+RESULTS:
    #+begin_example
    Data sets in package ‘MASS’:

    abbey                           Determinations of Nickel Content
    accdeaths                       Accidental Deaths in the US 1973-1978
    Aids2                           Australian AIDS Survival Data
    Animals                         Brain and Body Weights for 28 Species
    anorexia                        Anorexia Data on Weight Change
    bacteria                        Presence of Bacteria after Drug Treatments
    beav1                           Body Temperature Series of Beaver 1
    beav2                           Body Temperature Series of Beaver 2
    biopsy                          Biopsy Data on Breast Cancer Patients
    birthwt                         Risk Factors Associated with Low Infant Birth Weight
    Boston                          Housing Values in Suburbs of Boston
    cabbages                        Data from a cabbage field trial
    caith                           Colours of Eyes and Hair of People in Caithness
    Cars93                          Data from 93 Cars on Sale in the USA in 1993
    cats                            Anatomical Data from Domestic Cats
    cement                          Heat Evolved by Setting Cements
    chem                            Copper in Wholemeal Flour
    coop                            Co-operative Trial in Analytical Chemistry
    cpus                            Performance of Computer CPUs
    crabs                           Morphological Measurements on Leptograpsus Crabs
    Cushings                        Diagnostic Tests on Patients with Cushing's Syndrome
    DDT                             DDT in Kale
    deaths                          Monthly Deaths from Lung Diseases in the UK
    drivers                         Deaths of Car Drivers in Great Britain 1969-84
    eagles                          Foraging Ecology of Bald Eagles
    epil                            Seizure Counts for Epileptics
    farms                           Ecological Factors in Farm Management
    fgl                             Measurements of Forensic Glass Fragments
    forbes                          Forbes' Data on Boiling Points in the Alps
    GAGurine                        Level of GAG in Urine of Children
    galaxies                        Velocities for 82 Galaxies
    gehan                           Remission Times of Leukaemia Patients
    genotype                        Rat Genotype Data
    geyser                          Old Faithful Geyser Data
    gilgais                         Line Transect of Soil in Gilgai Territory
    hills                           Record Times in Scottish Hill Races
    housing                         Frequency Table from a Copenhagen Housing Conditions Survey
    immer                           Yields from a Barley Field Trial
    Insurance                       Numbers of Car Insurance claims
    leuk                            Survival Times and White Blood Counts for Leukaemia Patients
    mammals                         Brain and Body Weights for 62 Species of Land Mammals
    mcycle                          Data from a Simulated Motorcycle Accident
    Melanoma                        Survival from Malignant Melanoma
    menarche                        Age of Menarche in Warsaw
    michelson                       Michelson's Speed of Light Data
    minn38                          Minnesota High School Graduates of 1938
    motors                          Accelerated Life Testing of Motorettes
    muscle                          Effect of Calcium Chloride on Muscle Contraction in Rat Hearts
    newcomb                         Newcomb's Measurements of the Passage Time of Light
    nlschools                       Eighth-Grade Pupils in the Netherlands
    npk                             Classical N, P, K Factorial Experiment
    npr1                            US Naval Petroleum Reserve No. 1 data
    oats                            Data from an Oats Field Trial
    OME                             Tests of Auditory Perception in Children with OME
    painters                        The Painter's Data of de Piles
    petrol                          N. L. Prater's Petrol Refinery Data
    phones                          Belgium Phone Calls 1950-1973
    Pima.te                         Diabetes in Pima Indian Women
    Pima.tr                         Diabetes in Pima Indian Women
    Pima.tr2                        Diabetes in Pima Indian Women
    quine                           Absenteeism from School in Rural New South Wales
    Rabbit                          Blood Pressure in Rabbits
    road                            Road Accident Deaths in US States
    rotifer                         Numbers of Rotifers by Fluid Density
    Rubber                          Accelerated Testing of Tyre Rubber
    ships                           Ships Damage Data
    shoes                           Shoe wear data of Box, Hunter and Hunter
    shrimp                          Percentage of Shrimp in Shrimp Cocktail
    shuttle                         Space Shuttle Autolander Problem
    Sitka                           Growth Curves for Sitka Spruce Trees in 1988
    Sitka89                         Growth Curves for Sitka Spruce Trees in 1989
    Skye                            AFM Compositions of Aphyric Skye Lavas
    snails                          Snail Mortality Data
    SP500                           Returns of the Standard and Poors 500
    steam                           The Saturated Steam Pressure Data
    stormer                         The Stormer Viscometer Data
    survey                          Student Survey Data
    synth.te                        Synthetic Classification Problem
    synth.tr                        Synthetic Classification Problem
    topo                            Spatial Topographic Data
    Traffic                         Effect of Swedish Speed Limits on Accidents
    UScereal                        Nutritional and Marketing Information on US Cereals
    UScrime                         The Effect of Punishment Regimes on Crime Rates
    VA                              Veteran's Administration Lung Cancer Trial
    waders                          Counts of Waders at 15 Sites in South Africa
    whiteside                       House Insulation: Whiteside's Data
    wtloss                          Weight Loss Data from an Obese Patient
    #+end_example

** Introduction to R

- [X] Why we are using R
- [X] The R console
- [X] The R environment
- [X] R display options
- [X] R packages
- [X] "Tidyverse" vs. Base R
- [X] Light data exploration with R
- [ ] Customizing R at startup

* DONE Week 7: Arithmetic in R

** DONE About the last assignment

- Last exercise: The point was to realize how the shell,
  the console, and stdout work together.

- If you fail: fail early so that you can talk to me. And
  if you forgot - submit what you have.

** DONE Projects Submission (from the assignment)

*Deliverables for the 2nd sprint*

1. Find at least one scholarly article directly relevant to your
   project. Preferably find a literature review article (a paper that
   surveys many others).
2. Build a litmap for your chosen scholarly article using
   litmaps.com. Download the litmap to your GDrive repo.
3. Upload your sources (articles, websites, etc.) to NotebookLM.
   Update your project proposal according to the feedback that you
   received, and to any other insights that you might have had. Upload
   it to NotebookLM. Add the new references and upload that text to
   NotebookLM as well.
4. Write a detailed prompt to generate a NotebookLM video that contains:
   1) Your project’s motivation and question (from Sprint 1).
   2) The literature you found and what it tells you.
   3) The methodology you will use going forward.
   Upload the prompt to GDrive.
5. Upload the video to your team’s shared Google Drive.
6. Share your NotebookLM project with me as the process owner at
   birkenkrahe@lyon.edu.
7. Submit the video here in Canvas for grading.
8. Post your video link to the shared class Google Chat thread.

** IN PROGRESS Arithmetic in R

- [X] Please Excuse My Dear Aunt Sally (operator precedence)
- [X] Mathematical functions and formula translation
- [X] Logarithmic transformation, exp vs log
- [ ] Scientific notation and how to get rid of it.
- [ ] Special numbers and special functions in R
- [ ] Logical values and operators in R

* IN PROGRESS Week 8: 2nd sprint review / Special numbers & functions / vectors (Oct 13,15,17)
#+attr_html: :width 400px :float nil:
[[../img/homecomingR.png]]

- [X] 2nd sprint review
- [ ] DataCamp lesson: ~factor~ vectors (important!)
- [ ] Quick review: exp vs. log
- [ ] Special values and special functions in R 
- [ ] Logical values and logical functions in R
- [ ] Popquiz: Vectors and matrices
- [ ] Home assignment: Vectors and factors

** DONE Review: 2nd sprint review
#+attr_html: :width 400px :float nil:
[[../img/notebook.png]]

*** Feedback (yours)

- What's your view of this tool? What did you learn?

  1) Personal approach of the notebook (like it).
  2) More interactive: bot quizzed me on my prompt.
  3) Curated data (fewer hallucinations/lies/errors)
  4) Output not so easy to understand
  5) Formatting of the output is an issue
  6) Some controls are too hidden
  7) Freemium account has issues
  8) I could have done this on my own faster and better

*** Feedback (mine)

- You find my comments on Canvas (posted once per team/person).

*** Review: Q&A

In addition, please upload your prompt for the final video to
GDrive. *You may need to update the link to your GDrive in Canvas.*

- *Levi:* Comment on the claim made in the video that pharmacological
  research often uses small samples, and that "analysis methods are
  frequently inappropriate".
  #+begin_quote
  In reality, only early pharmacological studies are typically small
  and less open (less honest) due to commercial and legal
  pressure. Late stage studies (requiring regulatory approval) are
  supposed to be large scale - to ensure protection of humans. Another
  issue is when early stage trials have animal rather than human
  subjects. How is the transition from animal to human managed?

  NotebookLM: The sources confirm that pharmacological research often
  uses small samples (sometimes as low as n=3-4 per group) due to
  resource limitations, mandating the use of appropriate statistical
  methods—such as non-parametric tests, effect size estimates, and
  bootstrapping—to maximize insights and maintain rigor despite the
  resultant low statistical power.
  #+end_quote

- *Matthew:* Can you give another example for the proposed "power of
  borrowed ideas (as explained in the video)?
  #+begin_quote
  The invention of Velcro (By George de Mestral, 1941) is a textbook
  case of "biomimicry": borrowing an idea from nature to solve a human
  engineering problem. He noticed that burrs from plants stuck to fur
  and clothes. Under the microscope, he found hook-llike structures,
  which he turned into the design of Velcro ("velvet" + "crochet").

  NotebookLM: The problem of quantifying acoustic diversity in natural
  soundscapes was solved by directly borrowing and adapting classical
  ecological biodiversity indices, such as applying the Shannon
  Entropy (Shannon Index) and the Gini index (commonly used to
  estimate species evenness) to analyze the distribution of acoustic
  energy across the frequency spectrum
  #+end_quote

- *Olivia/Ava:* Given the analysis in the 2009 paper that you found,
  what is still left for you do to?
  #+begin_quote
  Possible answer: Especially given the issues around the article's
  main author (Bruno Frey), you should validate individual claims of
  the article, and find alternative sources of analysis. It would also
  be interesting to see what the findings mean in terms of social
  policy and social norms - what are they justifying? How have things
  changed since the early 1900s? Lastly, the article contains no
  visualizations whatsoever (no barcharts) - you could turn these
  tables into charts and compare them with the charts taken from the
  original dataset.

  NotebookLM answer (long answer saved in note): The project still
  needs to execute its planned quantitative analysis—including
  performing regression analysis and generating statistical
  visualizations to explore confounding variables like class
  interaction and embarkation port—and ultimately use these verified
  historical findings to inform and create new disaster plans.
  #+end_quote

- *Avash, Riya, Prabhat:* What kind of "hidden story" are you talking
  about at the end of your video?
  #+begin_quote
  For example: Sales increase steadily year-over-year. The hidden
  story: when segmenting by geography, urban vs. rural sales, it turns
  out that urban sales stagnate because of competition by online
  retailers, while rural sales surge. This could lead to a strategic
  repositioning in rural and urban areas.

  Answer by the notebook bot itself: "The sources do not provide the
  actual, specific concrete finding that constitutes the "hidden
  story," as the project was still in the proposal stage."
  #+end_quote

- *Diego, Matheus, Frederico:* Can you comment on the sample data that
  led to the suggestion that fixture congestion is correlated with
  injury risk? Are the data unequivocal (do they say the same thing)?
  #+begin_quote
  Response by your own notebook (since I could not access your
  articles) - full answer saved as a note: While short-term fixture
  congestion (e.g., consecutive matches with insufficient rest)
  generally increases match injury incidence, the data concerning
  training and overall injury incidence are inconsistent (sometimes
  showing a decrease due to training load management) and long-term
  fixture congestion may have no effect on overall injury rates.
  #+end_quote
  
- *Shaksham, Surendra, Jeniz:* How will your methodology be structured -
  will you collect data related to the three factors, or are you
  mining for broader, more qualitative insights, and how will you do
  this?
  #+begin_quote
  NotebookLM: We are aiming for broader, more qualitative meaningful
  insights into common student challenges and strategies, prioritizing
  our conceptual constraint of not replicating existing large-scale
  studies over strictly measuring the three identified factors (Time
  planning, Time attitudes, and Time wasting) found in the referenced
  academic paper. Example questions focus on: 1) what are your
  challenges, 2) what are your tools?, 3) what are your greatest
  distractions, 4) which habit helped you?

  Note: If you want to get primary data, you need to get approval from
  the Institutional Review Board [I thought you did not want to use
  primary data because of this? The approval process takes a while.]
  #+end_quote

*** Important: Author validation

- What's up with Bruno Frey? https://en.wikipedia.org/wiki/Bruno_Frey

g** NEXT Review: ~factor~ data structure in R
#+attr_html: :width 400px :float nil:
[[../img/factor.png]]

** TODO Vectors!
#+attr_html: :width 400px :float nil:
#+caption: Rocket launch: vectors!
[[../img/rocket.png]]

- [ ] We'll look at the popquiz answers together. Grade yourself.

- [ ] You have a home assignment for vectors and factors.

- [ ] Next week, we'll cover vector/matrix/factor systematically.


